{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xT7MKZuMRaCg"
   },
   "source": [
    "# Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wq4RCyyPSYRp"
   },
   "source": [
    "#### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGCtiXUhSWss"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D,MaxPool1D\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional,Flatten,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCPC_WN-eCyw"
   },
   "outputs": [],
   "source": [
    "# vocab_size is no.of words to consider from the dataset, ordering based on frequency.\n",
    "vocab_size = 10000 #vocab size\n",
    "maxlen = 300  #number of word used from each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMEsHYrWxdtk"
   },
   "source": [
    "#### Load the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0g381XzeCyz"
   },
   "outputs": [],
   "source": [
    "#load dataset as a list of ints\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "KafJmeRAVHlL",
    "outputId": "9a25c1bd-fa35-4e0f-b13f-1499f0b8474e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data  (25000,)\n",
      "train_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "test_data  (25000,)\n",
      "test_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "Maximum value of a word index \n",
      "9999\n",
      "Maximum length num words of review in train \n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data \", x_train.shape)\n",
    "print(\"train_labels \", y_train.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"test_data \", x_test.shape)\n",
    "print(\"test_labels \", y_test.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"Maximum value of a word index \")\n",
    "print(max([max(sequence) for sequence in x_train]))\n",
    "print(\"Maximum length num words of review in train \")\n",
    "print(max([len(sequence) for sequence in x_train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A10A-6PEXgMY"
   },
   "source": [
    "#### Get the word index and then Create a key-value pair for word and word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "REqVitkAWUFZ",
    "outputId": "30f896e8-621d-415a-ba8c-1032b11f09bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? as romantic comedies go this was a cute and winning one i thought that the writing could have been stronger to build up the final connection a bit better but that is not a huge ? point but amanda ? and scott wolf give nice performances and are as charming as ever these are two of my favorite actors and i was just glad to see them cast as romantic leads i hope to see them cast in more projects soon br br overall this movie won't change your life but is is sweet warm and winning not a bad thing to be at all\n"
     ]
    }
   ],
   "source": [
    "# See an actual review in words\n",
    "# Reverse from integers to words using the DICTIONARY\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "reverse_word_index = dict(\n",
    "[(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "decoded_review = ' '.join(\n",
    "[reverse_word_index.get(i - 3, '?') for i in x_train[345]])\n",
    "\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kj3bUfqAVG0F"
   },
   "outputs": [],
   "source": [
    "#make all sequences of the same length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test =  pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9eo_O_2KaOgM",
    "outputId": "53c0e7b0-537a-4f32-f7c0-71ba8e4c16df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data  (25000, 300)\n",
      "test_data  (25000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data \", x_train.shape)\n",
    "print(\"test_data \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dybtUgUReCy8"
   },
   "source": [
    "## Build Keras Embedding Layer Model\n",
    "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
    "\n",
    "* The embedding layer can be used at the start of a larger deep learning model. \n",
    "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
    "* Use the embedding layer to train our own word2vec models.\n",
    "\n",
    "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vdsTrbJYCpj"
   },
   "source": [
    "#### Build a Sequential Model using Keras for the Sentiment Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "TxNDNhrseCzA",
    "outputId": "5a766523-b0e1-4881-c784-890dfd3f188c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 32)           320000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 300, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 150, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 376,405\n",
      "Trainable params: 376,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, output_dim = 32, input_length = maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPool1D(pool_size = 2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))             \n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "QH-sc-YnkcfJ",
    "outputId": "1642766a-7435-4650-d549-655f8a8d13c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 135s 5ms/sample - loss: 0.4427 - acc: 0.7700 - val_loss: 0.2921 - val_acc: 0.8798\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 134s 5ms/sample - loss: 0.2246 - acc: 0.9143 - val_loss: 0.3071 - val_acc: 0.8713\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 134s 5ms/sample - loss: 0.1674 - acc: 0.9398 - val_loss: 0.3155 - val_acc: 0.8736\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "history = model.fit(x_train, y_train,batch_size=64,epochs=3,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkoUgJg_YJC8"
   },
   "source": [
    "#### the Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vkx-mn-Zo0Y"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "LhkR83uT4IKy",
    "outputId": "7f3cb926-40a8-4697-dd13-b03e9713ab3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8736\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     12500\n",
      "           1       0.91      0.83      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.88      0.87      0.87     25000\n",
      "weighted avg       0.88      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changing the shape of pred to 1-Dimensional\n",
    "ytest_prediction = np.array(pred).reshape((25000, ))\n",
    "for i in range(len(ytest_prediction)):\n",
    "    ytest_prediction[i] = round(ytest_prediction[i])\n",
    "ytest_prediction = ytest_prediction.astype(int)\n",
    "print(\"accuracy:\",accuracy_score(y_test,ytest_prediction))\n",
    "print(\"classification_report:\\n\",classification_report(y_test,ytest_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MgNYEV3_4FgG",
    "outputId": "a36a3ab9-6ab7-4595-c662-708c542e6c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc AUC socre is : 0.9481.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  roc_auc_score\n",
    "print(\"The roc AUC socre is : %.4f.\" %roc_auc_score(y_test, pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Igq8Qm8GeCzG"
   },
   "source": [
    "## Retrive the output of each layer in keras for a given single test sample from the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-dUDSg7VeCzM",
    "outputId": "b87ff3fe-210f-4e5d-af30-5c61d7d31f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- embedding  layer ---------- \n",
      "\n",
      "[[[-0.01104451 -0.07824421 -0.02044006 ... -0.01431841 -0.0074472\n",
      "    0.03292025]\n",
      "  [-0.01104451 -0.07824421 -0.02044006 ... -0.01431841 -0.0074472\n",
      "    0.03292025]\n",
      "  [-0.01104451 -0.07824421 -0.02044006 ... -0.01431841 -0.0074472\n",
      "    0.03292025]\n",
      "  ...\n",
      "  [-0.01511567 -0.09015582 -0.05512023 ... -0.03145565  0.03647319\n",
      "   -0.00206182]\n",
      "  [-0.00131926  0.03686389  0.00565225 ... -0.01578274  0.00599393\n",
      "    0.00061738]\n",
      "  [ 0.03404765  0.0072722  -0.01393873 ... -0.05090065  0.04384007\n",
      "    0.04650633]]]\n",
      "\n",
      " ---------- dropout  layer ---------- \n",
      "\n",
      "[[[-0.01104451 -0.07824421 -0.02044006 ... -0.01431841 -0.0074472\n",
      "    0.03292025]\n",
      "  [-0.01104451 -0.07824421 -0.02044006 ... -0.01431841 -0.0074472\n",
      "    0.03292025]\n",
      "  [-0.01104451 -0.07824421 -0.02044006 ... -0.01431841 -0.0074472\n",
      "    0.03292025]\n",
      "  ...\n",
      "  [ 0.03040791 -0.04417368  0.02203849 ... -0.01377411 -0.00967952\n",
      "    0.02545103]\n",
      "  [-0.01014464 -0.00710064 -0.02316453 ...  0.03871964  0.03896904\n",
      "   -0.03615612]\n",
      "  [-0.00988265 -0.01613916 -0.10293449 ...  0.00733185 -0.03543584\n",
      "   -0.01909673]]]\n",
      "\n",
      " ---------- conv1d  layer ---------- \n",
      "\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.01259482 ... 0.         0.         0.        ]\n",
      "  [0.07065699 0.         0.03141966 ... 0.2580251  0.01032068 0.07786861]\n",
      "  [0.09757316 0.         0.         ... 0.17430216 0.06972434 0.06102262]]]\n",
      "\n",
      " ---------- max_pooling1d  layer ---------- \n",
      "\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.0070919  0.         ... 0.         0.         0.        ]\n",
      "  [0.06686968 0.         0.         ... 0.01021412 0.         0.02306052]\n",
      "  [0.02617112 0.         0.02148543 ... 0.04589729 0.0325335  0.        ]]]\n",
      "\n",
      " ---------- lstm  layer ---------- \n",
      "\n",
      "[[ 0.10980192 -0.11893176 -0.08415292  0.00200724 -0.00766872  0.3260969\n",
      "  -0.30226427 -0.20925112 -0.07227366 -0.11318032  0.2974537  -0.13861847\n",
      "   0.0603859   0.11496942  0.33324757  0.08295704  0.15373027 -0.30433896\n",
      "   0.1042355  -0.23518905  0.34472978  0.12840302 -0.17551763 -0.07705915\n",
      "   0.141899    0.03857929  0.06126587 -0.28118792  0.19318575 -0.35260493\n",
      "  -0.23188923  0.10797859  0.5319194   0.00184419  0.14165586  0.32018197\n",
      "  -0.00598935 -0.19333525 -0.47825268 -0.25980347  0.3813288   0.20984793\n",
      "   0.14808412 -0.16268311 -0.34873635 -0.09590606  0.09257687  0.75280255\n",
      "  -0.07420813  0.15944435  0.22453867  0.2871562  -0.2575482  -0.16228515\n",
      "  -0.07866938 -0.6490987  -0.19651875  0.15364626  0.18828578  0.5800512\n",
      "   0.25487226 -0.0801109  -0.20379283  0.07273688  0.30065176  0.0412428\n",
      "  -0.05985903  0.1589948  -0.45022517  0.01304374  0.13815756  0.29530048\n",
      "  -0.07203877 -0.3135702  -0.25358573  0.270321   -0.07856918  0.2521524\n",
      "   0.3445151  -0.14519684 -0.07894833 -0.11697184 -0.27945438 -0.30458453\n",
      "  -0.0169291   0.41973722  0.02530927 -0.09302917 -0.09267291  0.31534418\n",
      "   0.35621342 -0.17700084 -0.16154687 -0.12532485  0.41270217 -0.2269594\n",
      "  -0.15798134 -0.05696958  0.28178313 -0.15880892]]\n",
      "\n",
      " ---------- dropout_1  layer ---------- \n",
      "\n",
      "[[ 0.0746818  -0.10069935 -0.04537837 -0.00217266 -0.00251446  0.21894184\n",
      "  -0.20670207 -0.18153176 -0.05609491 -0.10458017  0.2141274  -0.08254939\n",
      "   0.02774115  0.09941514  0.2537737   0.04693475  0.06528675 -0.20122306\n",
      "   0.06794218 -0.15972747  0.222458    0.08110158 -0.13889219 -0.0613732\n",
      "   0.07773694  0.01383864  0.05212471 -0.17027067  0.13622332 -0.19627982\n",
      "  -0.17542762  0.07094167  0.34318924 -0.00457287  0.08002257  0.19412546\n",
      "   0.00503711 -0.1638606  -0.3488796  -0.22316255  0.25111213  0.12174901\n",
      "   0.1174015  -0.08843999 -0.25801843 -0.07052836  0.04263889  0.5524245\n",
      "  -0.04616506  0.12300064  0.15965849  0.18773803 -0.1680784  -0.10180865\n",
      "  -0.02156938 -0.42060673 -0.12577361  0.1185461   0.1639459   0.33554095\n",
      "   0.17759651 -0.07770088 -0.13756986  0.06214364  0.18642205  0.01335645\n",
      "  -0.043887    0.14240284 -0.308958   -0.00658857  0.08776979  0.17404123\n",
      "  -0.02509126 -0.19921088 -0.17526497  0.19399036 -0.05916177  0.18302847\n",
      "   0.2671328  -0.08479652 -0.05914976 -0.09627432 -0.2158811  -0.21338136\n",
      "  -0.03368612  0.3183449   0.01145457 -0.04283036 -0.08366302  0.22133955\n",
      "   0.22042683 -0.12419347 -0.0988599  -0.10040259  0.31252033 -0.13308884\n",
      "  -0.11359712 -0.02149453  0.16542174 -0.10702641]]\n",
      "\n",
      " ---------- dense  layer ---------- \n",
      "\n",
      "[[0.0045462]]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                    outputs=model.get_layer(layer.name).output)\n",
    "    intermediate_output = intermediate_layer_model.predict(x_test[np.random.randint(25000)].reshape(1,-1))\n",
    "    print(\"\\n\",10*\"-\",layer.name,\" layer\",10*\"-\",\"\\n\")\n",
    "    print(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kn7rR4UXaWos"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SeqNLP_Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
